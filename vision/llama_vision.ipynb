{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Service - MUlti-Modal Llama model\n",
    "\n",
    " if you have errors running sample code reach out for help in #igiu-ai-learning\n",
    " \n",
    " other questions #igiu-innovation-lab or #oci_ai_vision_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the  variables\n",
    "\n",
    "\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from oci.generative_ai_inference.models import *\n",
    "import oci, base64\n",
    "import json, os \n",
    "\n",
    "#####\n",
    "#make sure your sandbox.json file is setup for your environment. You might have to specify the full path depending on  your `cwd` \n",
    "# you can also try making your cwd ofr jupyter match your workspace python code: \n",
    "# vscopde menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "# change from ${fileDirname} to ${workspaceFolder}\n",
    "#####\n",
    "\n",
    "#SANDBOX_CONFIG_FILE = \"~/work/code/python/workshop/sandbox.json\"\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.json\"\n",
    "#LLM_MODEL = \"meta.llama-3.2-90b-vision-instruct\" \n",
    "#LLM_MODEL = \"meta.llama-4-maverick-17b-128e-instruct-fp8\"\n",
    "LLM_MODEL = \"meta.llama-4-scout-17b-16e-instruct\"\n",
    "\n",
    "llm_service_endpoint= \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "\n",
    "PREAMBLE = None\n",
    "MESSAGE = \"tell me this image\"\n",
    "\n",
    "\n",
    "llm_client = None\n",
    "llm_payload = None\n",
    "FILE_TO_ANALYZE = \"./vision/dussera-b.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def get_message():\n",
    "        content1 = oci.generative_ai_inference.models.TextContent()\n",
    "        content1.text = \"tell me this image\"\n",
    "        content2 = oci.generative_ai_inference.models.ImageContent()\n",
    "        image_url = oci.generative_ai_inference.models.ImageUrl()\n",
    "        image_url.url = f\"data:image/jpeg;base64,{encode_image(FILE_TO_ANALYZE)}\"\n",
    "        content2.image_url = image_url\n",
    "        message = oci.generative_ai_inference.models.UserMessage()\n",
    "        message.content = [content1,content2] \n",
    "\n",
    "        return message\n",
    "\n",
    "def get_chat_request():\n",
    "        chat_request = oci.generative_ai_inference.models.GenericChatRequest()\n",
    "        #chat_request.preamble_override = \"you always answer in a one stanza poem.\"\n",
    "        #chat_request.message = get_message()\n",
    "        chat_request.messages = [get_message()]\n",
    "        chat_request.api_format = oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC\n",
    "        chat_request.num_generations = 1\n",
    "        chat_request.is_stream = False \n",
    "        chat_request.max_tokens = 500\n",
    "        chat_request.temperature = 0.75\n",
    "        chat_request.top_p = 0.7\n",
    "        chat_request.top_k = -1 \n",
    "        chat_request.frequency_penalty = 1.0\n",
    "\n",
    "        return chat_request\n",
    "\n",
    "def get_chat_detail (llm_request,compartmentId):\n",
    "        chat_detail = oci.generative_ai_inference.models.ChatDetails()\n",
    "        chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=\"meta.llama-3.2-90b-vision-instruct\")\n",
    "        chat_detail.compartment_id = compartmentId\n",
    "        chat_detail.chat_request = llm_request\n",
    "\n",
    "        return chat_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the keys and instantiate the client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scfg = None\n",
    "# read the sandbox config \n",
    "with open(os.path.expanduser(SANDBOX_CONFIG_FILE), 'r') as f:\n",
    "                scfg=  json.load(f)\n",
    "\n",
    "#read the oci config\n",
    "config = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]),scfg[\"oci\"][\"profile\"])\n",
    "\n",
    "llm_client = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
    "                config=config,\n",
    "                service_endpoint=llm_service_endpoint,\n",
    "                retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "                timeout=(10,240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the payload and call the client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_payload =get_chat_detail(get_chat_request(),scfg[\"oci\"][\"compartment\"])\n",
    "\n",
    "llm_response = llm_client.chat(llm_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_text = llm_response.data.chat_response.choices[0].message.content[0].text\n",
    "print (llm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 : Document Validator\n",
    "\n",
    "1. Create a document in PowerPoint with\n",
    "    * Name\n",
    "    * Address\n",
    "    * Dates \n",
    "    * Create date\n",
    "    * Expiry date\n",
    "    * Signature\n",
    "\n",
    "1. Save it as an image \n",
    "\n",
    "1. Use Document Understanding & LLM service to validate\n",
    "    *  is on correct name\n",
    "    *  is on correct address\n",
    "    *  is not expired\n",
    "    *  has a signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 : Form Filler\n",
    "\n",
    "1. Upload a receipt \n",
    "1. Fill out a expense report based on the receipt \n",
    "    *  Image an expense resporr as an multi line f string for simplicity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
