{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25a36f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "222552d2",
   "metadata": {},
   "source": [
    "## OCI Speech - Transcription \n",
    "\n",
    "helpful links\n",
    "- https://github.com/oracle/oci-python-sdk/tree/22fd62c8dbbd1aaed6b75754ec1ba8a3c16a4e5a/src/oci/ai_speech\n",
    "- https://docs.oracle.com/en-us/iaas/Content/speech/home.htm\n",
    "- #oci_speech_service_users or #igiu-innovation-lab slack channel \n",
    "- if you have errors running sample code reach out for help in #igiu-ai-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a46d5e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12753a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oci.ai_speech import AIServiceSpeechClient\n",
    "from oci.ai_speech.models import *\n",
    "from oci.config import from_file\n",
    "from oci.signer import load_private_key_from_file\n",
    "import oci\n",
    "from oci.object_storage import ObjectStorageClient\n",
    "import json,os,io,time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f561b1",
   "metadata": {},
   "source": [
    "## Set input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243e9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#make sure your sandbox.json file is setup for your environment. You might have to specify the full path depending on  your `cwd` \n",
    "# you can also try making your cwd ofr jupyter match your workspace python code: \n",
    "# vscopde menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "# change from ${fileDirname} to ${workspaceFolder}\n",
    "#####\n",
    "\n",
    "#SANDBOX_CONFIG_FILE = \"~/work/code/python/workshop/sandbox.json\"\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.json\"\n",
    "\n",
    "FILE_TO_ANALYZE = \"./speech/voice_sample1.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c722709",
   "metadata": {},
   "source": [
    "# Read the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ab8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "scfg = None\n",
    "# read the sandbox config \n",
    "with open(os.path.expanduser(SANDBOX_CONFIG_FILE), 'r') as f:\n",
    "                scfg=  json.load(f)\n",
    "oci_cfg = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]),scfg[\"oci\"][\"profile\"])\n",
    "bucket_cfg = scfg[\"bucket\"]\n",
    "namespace = bucket_cfg[\"namespace\"]\n",
    "bucketName =  bucket_cfg[\"bucketName\"]\n",
    "filename = os.path.basename(FILE_TO_ANALYZE)\n",
    "prefix = bucket_cfg['prefix']\n",
    "compartmentId =scfg[\"oci\"][\"compartment\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d686e",
   "metadata": {},
   "source": [
    "## Upload file  \n",
    "\n",
    "This is an optional step. If the file is already uploaded, no need to upload it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ca8a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file ./speech/voice_sample1.mp3 ...\n",
      "Upload completed !\n"
     ]
    }
   ],
   "source": [
    "object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "print(f\"Uploading file {FILE_TO_ANALYZE} ...\")\n",
    "object_storage_client.put_object(bucket_cfg[\"namespace\"], \n",
    "                                bucket_cfg[\"bucketName\"], \n",
    "                                f\"{bucket_cfg['prefix']}/{os.path.basename(FILE_TO_ANALYZE)}\", \n",
    "                                io.open(FILE_TO_ANALYZE,'rb'))\n",
    "print(\"Upload completed !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3659a889",
   "metadata": {},
   "source": [
    "## Create AI service Speech client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24901984",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_client =AIServiceSpeechClient(config=oci_cfg,signer= oci.signer.Signer(\n",
    "        tenancy=oci_cfg[\"tenancy\"],\n",
    "        user=oci_cfg[\"user\"],\n",
    "        fingerprint=oci_cfg[\"fingerprint\"],\n",
    "        private_key_file_location=oci_cfg[\"key_file\"]\n",
    "        ),\n",
    "        service_endpoint=\" https://speech.aiservice.us-phoenix-1.oci.oraclecloud.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372e6d8",
   "metadata": {},
   "source": [
    "## Set the input location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42b6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_location = oci.ai_speech.models.ObjectLocation(namespace_name=namespace, bucket_name=bucketName,\n",
    "                         object_names=[f\"{prefix}/{filename}\"]\n",
    "                         )\n",
    "input_location = oci.ai_speech.models.ObjectListInlineInputLocation(\n",
    "            location_type=\"OBJECT_LIST_INLINE_INPUT_LOCATION\", object_locations=[object_location])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4ddb4",
   "metadata": {},
   "source": [
    "## set the output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e27bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = oci.ai_speech.models.OutputLocation(namespace_name=namespace, bucket_name=bucketName, prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a177284",
   "metadata": {},
   "source": [
    "## Setup input feature \n",
    "You can specify the features you want to call. Note not all features are supported for all calls \n",
    "\n",
    "\n",
    "*******   ONLY RUN Either WHISPER or ORACLE MODELS ******\n",
    "### Oracle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983ccf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for Oracle model\n",
    "sample_normalization = oci.ai_speech.models.TranscriptionNormalization(is_punctuation_enabled=True)\n",
    "\n",
    "transcription_settings = oci.ai_speech.models.TranscriptionSettings(\n",
    "        diarization= oci.ai_speech.models.Diarization(is_diarization_enabled=True)  # dosnt specify number_of_speakers as its auto detected\n",
    "    )\n",
    "\n",
    "model_details = oci.ai_speech.models.TranscriptionModelDetails(\n",
    "        language_code=\"en-US\", \n",
    "        model_type=\"ORACLE\",\n",
    "        domain = \"GENERIC\",   # only generic domain is supported for now\n",
    "        transcription_settings =transcription_settings \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd19f9",
   "metadata": {},
   "source": [
    "******* ONLY RUN WHISPER OR ORACLE MODELS ******\n",
    "\n",
    "### Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5db718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for Whisper model\n",
    "sample_normalization = oci.ai_speech.models.TranscriptionNormalization(is_punctuation_enabled=True)\n",
    "\n",
    "transcription_settings = oci.ai_speech.models.TranscriptionSettings(\n",
    "        diarization= oci.ai_speech.models.Diarization(is_diarization_enabled=True)  # dosnt specify number_of_speakers as its auto detected\n",
    "    )\n",
    "model_details = oci.ai_speech.models.TranscriptionModelDetails(\n",
    "        language_code=\"en\", \n",
    "        model_type=\"WHISPER_MEDIUM\",\n",
    "        domain = \"GENERIC\",   # only generic domain is supported for now\n",
    "        transcription_settings =transcription_settings \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59ec19",
   "metadata": {},
   "source": [
    "## Create Speech Analysis detaiis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e27e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Transcription Job with details provided\n",
    "transcription_job_details = oci.ai_speech.models.CreateTranscriptionJobDetails(display_name=\"WorkshopTest\",\n",
    "    compartment_id=compartmentId,\n",
    "    description=\"Testing Oracle Speech Speech to Text\",\n",
    "    model_details=model_details,\n",
    "    input_location=input_location,\n",
    "    additional_transcription_formats=[\"SRT\"],\n",
    "    normalization=sample_normalization,\n",
    "    output_location=output_location\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f153e0",
   "metadata": {},
   "source": [
    "## Run the job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a695df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription Job ID: ocid1.aispeechtranscriptionjob.oc1.phx.amaaaaaaghwivzaarvo2xdwyfdgjnxbzrlcujkloolvxobd5ekcmkhzdm7vq.\n"
     ]
    }
   ],
   "source": [
    "transcription_job = None\n",
    "try:\n",
    "    transcription_job = speech_client.create_transcription_job(create_transcription_job_details=transcription_job_details)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    transcribe_job_id = transcription_job.data.id\n",
    "    print(f\"Transcription Job ID: {transcribe_job_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc8ee5",
   "metadata": {},
   "source": [
    "## Poll the job till it completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f47f4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: SUCCEEDEDSS\n",
      "Transcription job completed successfully!\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "while True:\n",
    "    transcribtion_job = speech_client.get_transcription_job(transcribe_job_id)\n",
    "    job_status = transcribtion_job.data.lifecycle_state\n",
    "    print(f\"Current Status: {job_status}\", end='\\r')\n",
    "    \n",
    "    if job_status == \"SUCCEEDED\":\n",
    "        print(\"\\nTranscription job completed successfully!\")\n",
    "        data = transcribtion_job.data        \n",
    "        break\n",
    "    elif job_status == \"FAILED\":\n",
    "        print(\"\\nTranscription job failed.\")\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(5)  # Wait 30 seconds before checking again "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393c8b7",
   "metadata": {},
   "source": [
    "## retrive the transcribed files \n",
    "\n",
    "as we have also asked for SRT file we will retrive all files in the subdirectory created by the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c3de5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ./speech/voice_sample1.mp3.json\n",
      "saved ./speech/voice_sample1.mp3.srt\n"
     ]
    }
   ],
   "source": [
    "object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "# iterate through all files in the prefix \n",
    "list_objects_response = object_storage_client.list_objects(\n",
    "        namespace_name=namespace,\n",
    "        bucket_name=bucketName, \n",
    "        prefix=data.output_location.prefix\n",
    "    )\n",
    "for obj in list_objects_response.data.objects:\n",
    "    response  = object_storage_client.get_object(namespace, bucketName, obj.name)\n",
    "    _, file_extension = os.path.splitext(obj.name)\n",
    "    filename = f\"{FILE_TO_ANALYZE}{file_extension}\"\n",
    "    with open(filename,\"w\") as f:\n",
    "        f.write(response.data.text)\n",
    "    print (f\"saved {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a092c92d",
   "metadata": {},
   "source": [
    "## Exercise : transcription\n",
    "\n",
    "1. Create an App that  takes in an audio\n",
    "    * Uses diarization to transcribe\n",
    "    * Compare Oracle & Wisper models\n",
    "    * Compare with original question  ( from tts exercise)\n",
    "\n",
    "1. Take an zoom recording\n",
    "    * Transcribe\n",
    "      * With captions\n",
    "    * Summarize using llm\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
